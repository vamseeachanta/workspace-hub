---
id: WRK-236
title: Test health trends — track test-writing pairing with code-writing sessions
status: pending
priority: medium
complexity: medium
compound: false
created_at: 2026-02-20T00:00:00Z
target_repos:
  - workspace-hub
commit:
spec_ref:
related: [WRK-231, WRK-229]
blocked_by: [WRK-231]
synced_to: []
plan_reviewed: false
plan_approved: false
standing: false
auto_execute: false
percent_complete: 0
brochure_status: n/a
computer: ace-linux-1
---

# Test health trends — track test-writing pairing with code-writing sessions

## What

Add test health tracking to the session analysis pipeline (WRK-231). For every session that writes or modifies implementation code, measure whether a corresponding test was written, and track coverage delta across sessions. Surface sessions that write code without tests as a quality signal.

## Why

TDD is mandatory per rules, but there is no mechanism to verify it is actually happening across sessions. A session that writes implementation code without a matching test is a silent rule violation. Tracking this across sessions reveals whether the practice is holding — or eroding — and which repos or WRK items are the culprits.

## Scope

- During session analysis (WRK-231 morning cron), detect sessions where:
  - Implementation files were written/edited (non-test `.py`, `.ts`, `.js` etc.)
  - No corresponding test file was written or modified in the same session
- Track per-repo coverage delta where `pytest --cov` or equivalent is available
- Flag sessions with code-without-tests as TDD rule violations
- Aggregate trend: is the code-to-test pairing rate improving or declining over time?

## Integration

Feeds into WRK-231 session analysis output. Add to `session-analysis/YYYY-MM-DD-HH.md` report:
- `tdd_pairing_rate`: % of code-writing sessions that also wrote tests
- `uncovered_sessions`: list of sessions with code but no test changes
- `repos_at_risk`: repos with declining coverage delta over last 30 sessions

## Acceptance Criteria

- [ ] Session analysis detects code-without-test sessions (implementation file changed, no test file changed)
- [ ] TDD pairing rate tracked per session and as 30-session rolling average
- [ ] Coverage delta tracked per repo where coverage tooling is available (assethold, digitalmodel, worldenergydata)
- [ ] Sessions below threshold flagged and included in session analysis summary
- [ ] Trend surfaces in morning cron report: improving / flat / declining
- [ ] Deep decline (3 consecutive sessions without tests) → auto-create WRK item or preflight warning

## Agentic AI Horizon

- Models in 3–4 months will generate tests reliably — but tracking whether they do is still valuable; this metric becomes an agent quality score for the code-writing capability
- Low effort to instrument, high value as a quality guardrail — do now while setting up WRK-231 infrastructure

---
*Source: "yes and add separate work item in queue for 5 and 6 so we do not have to rethink same things again" — item 5 (test health trends)*
