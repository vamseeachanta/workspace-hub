---
id: WRK-251
title: "Dynacard vision model evaluation — benchmark GPT-4V / Claude Vision vs current heuristics"
status: pending
priority: medium
complexity: medium
compound: false
created_at: 2026-02-20T00:00:00Z
target_repos:
  - digitalmodel
commit:
spec_ref:
related: [WRK-093]
blocked_by: []
synced_to: []
plan_reviewed: false
plan_approved: false
percent_complete: 0
brochure_status: n/a
---

# Dynacard vision model evaluation — benchmark GPT-4V / Claude Vision vs current heuristics

## What
Evaluate replacing or augmenting dynacard pump card pattern recognition heuristics with vision model classification (Claude Vision / GPT-4V). Benchmark accuracy against the current WRK-093 implementation using a held-out test set of labelled pump cards.

## Why
The current implementation uses manual heuristics. Multimodal models available today can classify pump card patterns directly from images — a potential step change in accuracy. The current implementation is a good baseline for comparison.

## Acceptance Criteria
- [ ] Test set of N≥50 labelled pump cards assembled
- [ ] Vision model classification run against the full test set
- [ ] Accuracy measured and compared against current heuristics (WRK-093)
- [ ] Recommendation documented: replace / augment / keep heuristics
- [ ] Decision recorded in `.claude/docs/decisions/`

## Agentic AI Horizon
- Clear case where model improvements create a capability step-change — vision models are directly applicable to pump card image classification
- Current heuristic baseline (WRK-093) provides a clean comparison point
- **Disposition: do now if baseline shows clear win; park 2-3 months** if vision API quality is borderline — evaluation itself is low cost and determines the answer
