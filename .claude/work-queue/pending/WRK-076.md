---
id: WRK-076
title: Add data collection scheduler/orchestrator for automated refresh pipelines
status: pending
priority: medium
complexity: complex
compound: false
created_at: 2026-02-02T14:00:00Z
target_repos:
  - worldenergydata
commit:
spec_ref:
related: [WRK-073]
blocked_by: []
synced_to: []
provider: codex
---

# Add data collection scheduler/orchestrator for automated refresh pipelines

## What
Implement cron-style or task-queue automation for data refresh pipelines. Currently all data collection requires manual CLI invocation. The website claims "automated collection" and "real-time data refresh with smart caching" — this needs to be true.

## Why
Manual-only data collection contradicts the website's marketing claims. A scheduler enables "set and forget" data pipelines, which is the core value proposition for data-as-a-service clients.

## Acceptance Criteria
- [ ] Scheduler can run BSEE, SODIR, and Canada data refresh on configurable intervals
- [ ] Supports cron-like scheduling (daily, weekly, monthly)
- [ ] Logging and alerting on failures
- [ ] Idempotent — safe to re-run without data corruption
- [ ] CLI command to start/stop/status the scheduler
- [ ] Configuration via YAML
- [ ] Works as background service or systemd unit

## Plan

**Target**: `src/worldenergydata/scheduler/`

### Existing Assets (reuse)
- `bsee/data/acquirers/` — BSEE data acquisition scripts
- `sodir/` — SODIR data acquisition
- `metocean/data_sources/` — 6 API clients
- `marine_safety/importers/` — 9 importers

### Phase 1 — Scheduler Framework
- **Design decision**: evaluate cron-based execution (each job as standalone script, triggered by system cron) vs persistent scheduler process (`schedule` library). Recommend cron for simplicity unless sub-hourly scheduling is needed. Choose one approach — do not maintain dual paths.
- `scheduler.py`:
  - If cron-based: wrapper script per job with lock file for concurrency safety
  - If persistent: lightweight scheduler using Python `schedule` library (pip install)
  - YAML config: list of jobs with name, module, function, interval (daily/weekly/monthly), time
  - Job registry: define interface and auto-discovery mechanism for data source adapters
  - Idempotent execution: check last-run timestamp, skip if within interval
  - Log retention and rotation strategy (e.g., logrotate config or max 30 days)

### Phase 2 — Data Source Adapters
- `jobs/bsee_refresh.py` — Run BSEE production data refresh
- `jobs/sodir_refresh.py` — Run SODIR data refresh
- `jobs/metocean_refresh.py` — Refresh metocean data for tracked locations
- `jobs/marine_safety_refresh.py` — Run marine safety importers
- Each adapter: standardized interface `def run(config: dict) -> JobResult`

### Phase 3 — Monitoring & Alerting
- `monitor.py`:
  - Job execution logging with timestamps, duration, record counts
  - Failure detection with configurable retry (max 3 attempts, exponential backoff)
  - **Partial success handling**: each job runs independently; failure in one job does not prevent others from executing; status report shows per-job success/failure
  - Status report: last successful run per job, next scheduled run
  - Alert output: JSON status file + optional webhook notification (URL configurable in YAML). No email notification (no email infrastructure exists).

### Phase 4 — Service Integration
- `cli.py` — `python -m worldenergydata.scheduler start|stop|status`
- Systemd unit file template: `config/systemd/worldenergydata-scheduler.service`
- Config: `config/scheduler/scheduler_config.yml`

### Phase 5 — Tests
- Scheduler logic tests with mock clock
- Job adapter tests (mock data source, verify idempotent re-run)
- Config parsing tests

### Review Notes
- **Verdict**: Claude: MINOR | Codex: MINOR | Gemini: APPROVE
- **Actions taken**:
  - Added cron vs persistent scheduler design decision in Phase 1; recommend choosing one approach
  - Added job registry interface and auto-discovery mechanism per Codex feedback
  - Added log retention and rotation strategy
  - Added partial success handling: per-job independence
  - Replaced email notification with JSON status file + optional webhook (no email infra exists)
  - Added adapter complexity note: each data source has different invocation patterns
- *Cross-reviewed: 2026-02-09*

*Approved by user: 2026-02-09*

---
*Source: Gap analysis — all data collection is manual CLI; website claims automated collection*
