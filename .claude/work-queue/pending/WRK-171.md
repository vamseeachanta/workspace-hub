---
id: WRK-171
title: "Cost data calibration — sanctioned project benchmarking & multivariate cost prediction"
status: pending
priority: medium
complexity: complex
compound: true
created_at: 2026-02-17T00:00:00Z
target_repos:
  - worldenergydata
target_module: cost
commit:
spec_ref:
related: [WRK-019]
blocked_by: []
synced_to: []
plan_reviewed: false
plan_approved: false
percent_complete: 0
brochure_status: n/a
provider: claude
provider_alt:
group:
tags: [cost-data, benchmarking, machine-learning, field-economics, multivariate]
---

# Cost Data Calibration — Sanctioned Project Benchmarking & Multivariate Cost Prediction

## Context

The WRK-019 cost module uses proxy day rates (industry benchmark estimates, not ground truth). When building field development architecture, we need calibrated cost data derived from actual sanctioned project expenditures to produce credible field economics.

## What

A multi-phase effort to collect real sanctioned project cost data, build a structured calibration dataset, train a multivariate cost prediction model, and integrate calibrated rates back into the WRK-019 cost engine.

## Why

- Proxy day rates carry unknown bias — could be 20-50% off for specific region/depth/rig-type cells
- Field development economics require defensible cost inputs for investment decisions
- A calibrated model with confidence intervals lets users distinguish high-confidence estimates from extrapolations
- Industry benchmarking positions the cost module as a credible engineering tool, not just a lookup table

## Acceptance Criteria

- [ ] Sanctioned project cost dataset with at least 100 data points across multiple regions
- [ ] Structured schema covering region, water depth, well depth, operator, year, rig type, activity type, HPHT flag, subsea vs dry tree
- [ ] Multivariate cost prediction model trained and validated
- [ ] Quantified comparison: calibrated rates vs WRK-019 proxy rates (bias, RMSE per cell)
- [ ] Updated `day_rates.yml` with calibrated rates and confidence labels
- [ ] Proxy fallback retained for sparse cells
- [ ] Tests covering model training, prediction, and integration paths

## Plan

### Phase 1 — Data Collection & Web Scraping

Collect sanctioned project cost data from public sources:

- **FID announcements** with disclosed total project costs and per-well breakdowns
- **Operator annual reports & SEC filings** — 10-K (US operators), 20-F (foreign filers), annual statements from publicly traded E&P and drilling companies. MD&A sections and capital expenditure notes often break out per-project or per-region drilling/completion costs. Key targets: Shell, BP, Equinor, Petrobras, TotalEnergies, Chevron, ExxonMobil, Hess, Murphy, LLOG, etc.
- **Drilling contractor financial statements** — Transocean, Valaris, Noble, Diamond Offshore, Seadrill, Borr Drilling annual reports disclose fleet-level day rates, utilization, and contract economics
- **BOEM cost study reports** (publicly published GOM development cost studies)
- **IHS/Rystad/Wood Mackenzie** summary data where publicly available (conference papers, press releases)
- **Industry conference presentations** (OTC, SPE, IADC) with cost benchmarks
- **Regulatory filings** (Norwegian Petroleum Directorate, UK OGA/NSTA) with project cost disclosures

Deliverable: Raw collected data with source attribution and access dates.

### Phase 2 — Dataset Construction & Schema

Build a structured cost calibration dataset with fields:

| Field | Description | Example |
|-------|-------------|---------|
| `project_name` | Sanctioned project name | "Mad Dog Phase 2" |
| `region` | Geographic region | GOM, North Sea, Brazil, West Africa, Asia-Pacific |
| `water_depth_m` | Water depth in meters | 1,524 |
| `water_depth_band` | Categorical band | shallow / mid / deep / ultra-deep |
| `well_depth_m` | Total well depth (TVD or MD) | 8,200 |
| `well_depth_band` | Categorical band | shallow / medium / deep / ultra-deep |
| `operator` | Operating company | BP |
| `year_sanction` | Year of FID/sanction | 2017 |
| `year_drilling` | Year(s) of drilling activity | 2019 |
| `rig_type` | Rig type used | drillship / semi-sub / jack-up / platform |
| `activity_type` | Activity category | drilling / completion / intervention |
| `hpht` | High pressure / high temperature flag | true / false |
| `subsea` | Subsea vs dry tree | subsea / dry_tree |
| `cost_usd_mm` | Cost in millions USD | 145.0 |
| `cost_type` | What the cost covers | well_cost / day_rate / total_capex |
| `source` | Data source reference | "BP Annual Report 2019, p.47" |
| `confidence` | Data quality assessment | high / medium / low |

Deliverable: Cleaned CSV/Parquet dataset with consistent units and validated entries.

### Phase 3 — Multivariate Cost Prediction Model

Train a cost prediction model on the calibration dataset:

1. **Feature engineering**: encode categoricals, create interaction terms (region x depth, rig_type x hpht), inflation-adjust costs to common base year
2. **Baseline model**: Linear regression with interaction terms — interpretable, auditable
3. **Enhanced model**: Gradient-boosted trees (XGBoost/LightGBM) if linear model underfits
4. **Validation**: k-fold cross-validation, hold-out test set, per-cell RMSE and bias
5. **Comparison**: predict costs for WRK-019 proxy rate cells, quantify divergence
6. **Output**: confidence intervals per prediction (bootstrap or quantile regression)

Deliverable: Trained model, validation report, comparison table (calibrated vs proxy).

### Phase 4 — Integration with WRK-019 Cost Engine

Update the cost engine to use calibrated rates:

1. Generate calibrated `day_rates.yml` entries from model predictions
2. Add `confidence` field to each rate cell: `"high"` (calibrated, >5 data points), `"medium"` (proxy or sparse), `"low"` (extrapolated)
3. Retain proxy rates as fallback for cells with no calibration data
4. Add cost trend extrapolation: year-over-year escalation factors derived from the dataset
5. Update cost engine API to expose confidence metadata alongside rate estimates
6. Integration tests: verify cost engine produces calibrated rates where available, falls back to proxy otherwise

Deliverable: Updated cost engine with calibrated rates, confidence metadata, and trend extrapolation.

## Dependencies

- **WRK-019** (done) — provides the cost engine framework and proxy `day_rates.yml`

## Notes

- Data collection will be iterative — start with easily accessible public sources (BOEM, operator reports), then expand
- Cost normalization is critical: different sources report well cost, day rate, or total capex — must standardize
- Inflation adjustment needed for multi-year comparisons (use BLS CPI or IHS CERA upstream capital cost index)
- The linear regression baseline is non-negotiable before trying ML — interpretability matters for engineering credibility
- Consider building a web scraper module under `src/worldenergydata/cost/data_collection/` for repeatable data ingestion

## Agentic AI Horizon

- Cost data calibration using sanctioned project benchmarks makes the WRK-019 cost engine defensible for client presentations — critical for commercialising the field economics capability.
- Cost benchmarking against real sanctioned projects requires domain expertise to identify and validate sources; not superseded by AI improvements.
- **Disposition: do now** — calibrated cost data is what separates an interesting internal tool from a client-billable deliverable; execute after WRK-019 foundation is in place.
