---
id: WRK-164
title: "Well production test data quality and nodal analysis foundation"
status: pending
priority: high
complexity: complex
compound: false
created_at: 2026-02-16T00:00:00Z
target_repos:
  - worldenergydata
  - digitalmodel
target_module: production_engineering
commit:
spec_ref:
related: [WRK-019, WRK-077, WRK-111, WRK-153, WRK-163]
blocked_by: []
synced_to: []
plan: inline
plan_reviewed: true
plan_approved: true
percent_complete: 0
brochure_status: n/a
provider: claude
provider_alt:
task_agents:
  phase_1: codex    # Production test quality scorer — algorithm
  phase_2: codex    # VLP correlations + IPR models — algorithm
  phase_3: codex    # GIGO detector + reconciliation
  phase_4: codex    # Tests & examples
group:
---

# Well Production Test Data Quality & Nodal Analysis Foundation

## User Voice (Production / Reservoir Engineer)

> "This briefing document synthesizes key approaches to maximizing asset value, ranging from foundational Nodal Analysis to advanced Machine Learning and Genetic Algorithms."
>
> It is a good strategy document, looks nice in paper, but the king and emperor of a reliable nodal analysis is not having the best machine learning algorithms or AI; it is having the best well production test data. No question about it.
>
> Without a good nodal analysis, forget about well or field optimization. Believe me, I have been there, done that. It is one of the simplest things to do in the universe and keeps you head scratching every time. Not even the premier AI oil and gas service companies — we tried four — could be nearly close to a real optimization because the quality of well production test data is affected by the nonlinearity of interaction of the fluids (remember it is multiphase), rate, pseudo-steady state, and pressure.
>
> I bring up the nonlinearity term because we generally get tempted in using statistical tools for flow rate prediction, such as statistics, data science, and machine learning. T.h.e.y. w.i.l.l. n.o.t. w.o.r.k. These disciplines struggle with dynamical nonlinear systems. Don't bring a screwdriver to remove a spark plug!
>
> I am not even talking about operators taking bad measurements, or your multimillion $ MPFM. It is the nature of the beast in the field. There is not one well variable that behaves in a predictable way; everything is nonlinear. They are affected by watercut, GOR, pressure, temperature, size of the choke, contributing separator, flowline, stabilization time, test duration, fluid pattern. It is even more complex in gas lift wells. You could be close in some instances, when you have near perfect operating points and reliable VLP curves, but most of the time you don't.
>
> In my humble opinion, it is still our lack of understanding of the physics during well production tests. How we interpret and take the field readings. The problem is not in the nodal analysis software, it is in the data feed of the well models. GIGO. A production well test seems to be the easiest thing in the world, right?
>
> Wrong!
>
> Production well tests are misunderstood, relegated, unappreciated, ignored, and trivialized. And yet it is the most potent revenue generating tool. That is where your oilfield optimization path starts.
>
> There is plenty of room for physics, solvers, and algorithms at the crucial time of well production tests. The physics there is still unknown.

## Problem Statement

The industry's production optimization problem is **not a software or algorithm problem — it is a data quality problem rooted in unresolved multiphase flow physics**.

### Why ML/AI Fails for Production Optimization

| Approach | Assumption | Reality |
|----------|-----------|---------|
| Statistical / ML | Patterns repeat; relationships are learnable from data | Multiphase flow is dynamically nonlinear; relationships shift with operating conditions |
| Data science | More data → better predictions | More noisy data → more confident wrong answers (GIGO) |
| Genetic algorithms | Search space is well-defined | Operating point validity depends on unmeasured physics |
| Physics-based nodal | IPR + VLP intersection gives operating point | Only as good as the production test data feeding the well model |

### The Nonlinearity Problem

Well production test data quality is degraded by the nonlinear interaction of:

- **Watercut** — changes fluid properties, pressure drop, flow regime
- **GOR** — gas breakout changes density, viscosity, holdup
- **Pressure** — reservoir depletion, drawdown, pseudo-steady state transience
- **Temperature** — PVT properties shift with depth and time
- **Choke size** — critical vs. subcritical flow regimes
- **Separator conditions** — back-pressure, liquid level, gas handling
- **Flowline effects** — terrain, length, roughness, multiphase accumulation
- **Stabilization time** — most tests are too short for true stabilization
- **Test duration** — rate changes during test invalidate steady-state assumption
- **Fluid pattern** — slug, annular, bubble, stratified flow regimes
- **Gas lift** — adds another degree of freedom; gas lift valve performance, injection depth, casing-tubing communication

### The Core Insight

> "Production well tests are misunderstood, relegated, unappreciated, ignored, and trivialized. And yet it is the most potent revenue generating tool."

The optimization path is:
```
Good production test → Reliable well model → Valid nodal analysis → Real optimization
```

Breaking this chain at step 1 makes everything downstream unreliable. Four premier AI O&G service companies failed not because their algorithms were wrong, but because the input data was wrong.

## What

A production engineering module that starts from the **data quality end** rather than the **algorithm end**:

### Phase 1: Production Test Quality Assessment

- **Test quality scorer** — evaluate a production test record against physics-based criteria (stabilization, rate consistency, pressure equilibrium, separator conditions)
- **Nonlinearity flags** — detect conditions where test data is unreliable (transient flow, slug flow indicators, gas lift instability, choke criticality transitions)
- **Test protocol templates** — recommended test procedures by well type (flowing, gas lift, ESP, rod pump) with minimum stabilization times, measurement frequency, and QC checks

### Phase 2: Nodal Analysis Engine

- **VLP correlations** — Beggs & Brill, Orkiszewski, Gray, Hagedorn-Brown, Aziz-Govier-Fogarasi (selectable, not a single "best" one)
- **IPR models** — Vogel, Fetkovich, composite (undersaturated + saturated), with productivity index calibration from test data
- **Nodal solver** — IPR/VLP intersection with confidence bounds based on test data quality score
- **Sensitivity framework** — parametric sweeps on the variables that actually matter (choke size, separator pressure, gas lift rate, watercut progression)

### Phase 3: Data Quality → Model Confidence Pipeline

- **GIGO detector** — compare model-predicted rates against test rates; flag divergence with physics-based diagnosis (not statistical residuals)
- **Test-to-model reconciliation** — structured workflow: raw test → QC → correct → calibrate → validate → deploy
- **Confidence classification** — Green (test supports model), Amber (test has known issues, model adjusted), Red (test unreliable, model uses engineering judgement)

## Why

- **GTM value**: This is a pain point every production engineer lives daily. A tool that scores production test quality and links it to nodal analysis confidence speaks their language. The insight that "4 AI service companies failed" is a powerful positioning statement against pure-ML competitors.
- **Data linkage**: Connects to BSEE production data (WRK-077 decline curves, WRK-111 field analytics), drilling cost data (WRK-019), and the risk empowerment framework (WRK-163 — production test quality is a strategic risk that the well planning team often can't control).
- **Differentiation**: Everyone builds the nodal analysis engine. Nobody builds the production test quality assessment that determines whether the engine output is trustworthy.

## Connection to WRK-163 (Risk Empowerment)

The production engineer's pain point mirrors the drilling engineer's: they can see the problem (bad test data) but may not control the lever (test procedures are often dictated by operations, not production engineering). In the risk empowerment framework:

| Risk | Tier | Authority | Lever |
|------|------|-----------|-------|
| Test stabilization time too short | Operational | Production engineer | Request longer test duration |
| MPFM calibration drift | Tactical | Production + instrumentation | Scheduled recalibration program |
| Test separator not available | Strategic | Operations / asset management | Facility modification or dedicated test separator |
| Well test deferred for production targets | Strategic | Asset manager / corporate | Policy: test frequency vs. deferred production |

## Acceptance Criteria

- [ ] Production test quality scoring model defined (criteria, weights, thresholds)
- [ ] Nonlinearity flag taxonomy for common failure modes
- [ ] At least 2 VLP correlations implemented with test calibration
- [ ] At least 2 IPR models implemented with productivity index fitting
- [ ] Nodal solver with confidence bounds from test quality score
- [ ] GIGO detector comparing model vs. test with physics-based diagnostics
- [ ] Test-to-model reconciliation workflow documented
- [ ] Test suite with synthetic well scenarios (flowing, gas lift, high watercut, high GOR)
- [ ] BSEE production data integration for decline curve cross-validation (WRK-077)

## Plan

**Target**: `src/digitalmodel/production_engineering/` (new module) + `src/worldenergydata/production/` (data integration)

### Existing Assets (reuse)
| Component | Path | Purpose |
|-----------|------|---------|
| BSEE production data | `worldenergydata/bsee/production/` | Monthly production records |
| Decline curves (WRK-077) | `worldenergydata/bsee/production/decline_curves/` | DCA models for cross-validation |
| Field analytics (WRK-111) | `worldenergydata/bsee/production/field_analytics/` | Field-level aggregation |
| Strategy pattern | `structural/analysis/wall_thickness_codes/` | Registry + strategy for VLP correlations |

### Phase 1 — Production Test Quality Scorer (~300 lines)
- `test_quality_scorer.py`: evaluate test record against physics-based criteria
  - Stabilization check: rate change over test duration < threshold
  - Pressure equilibrium: flowing pressure vs static gradient
  - Separator conditions: back-pressure stability
  - Gas lift stability: injection rate consistency
- Output: quality score (0-100) + flag taxonomy
- `nonlinearity_flags.py`: detect unreliable conditions
  - Transient flow indicators
  - Slug flow signatures (pressure oscillation amplitude/frequency)
  - Gas lift instability (injection rate variance)
  - Choke criticality transitions (pressure ratio)

### Phase 2 — VLP Correlations + IPR Models (~500 lines)
- `vlp_correlations.py`: selectable correlations
  - Beggs & Brill (1973): general multiphase, inclination correction
  - Hagedorn-Brown (1965): vertical wells, liquid holdup correlation
  - Gray (1974): gas wells, condensate loading
- `ipr_models.py`: inflow performance
  - Vogel (1968): solution-gas drive below bubble point
  - Fetkovich (1973): isochronal test-based
  - Composite: undersaturated (linear) + saturated (Vogel)
  - PI calibration from test data
- `nodal_solver.py`: IPR/VLP intersection
  - Iterative solver (bisection + Newton refinement)
  - Confidence bounds from test quality score
  - Multiple operating point detection (unstable wells)

### Phase 3 — GIGO Detector + Reconciliation (~200 lines)
- `gigo_detector.py`: compare model-predicted vs test rates
  - Physics-based diagnosis (not statistical residuals)
  - Flag: "model expects X bbl/d at Y psi, test shows Z — likely cause: [watercut change / gas breakout / stabilization]"
- `reconciliation_workflow.py`: structured pipeline
  - Raw test -> QC (quality scorer) -> Correct (outlier removal) -> Calibrate (PI fitting) -> Validate -> Deploy
- Confidence classification: Green / Amber / Red

### Phase 4 — Tests & Examples
- Synthetic well scenarios: flowing, gas lift, high watercut, high GOR
- VLP correlation validation against published charts (Beggs & Brill Fig. 4.1)
- IPR validation against Vogel's original paper data
- Nodal solver convergence with known operating points
- BSEE production data integration for decline curve cross-validation
- Target: 50+ tests

### Dependencies
- No external software — pure Python + NumPy/SciPy
- BSEE production data (existing, may need LFS pull for detailed records)
- Reference: Beggs "Production Optimization Using Nodal Analysis"

## References

- Beggs, H.D. "Production Optimization Using Nodal Analysis"
- Brown, K.E. "The Technology of Artificial Lift Methods"
- Economides, M.J., Hill, A.D., Ehlig-Economides, C. "Petroleum Production Systems"
- Vogel, J.V. (1968) "Inflow Performance Relationships for Solution-Gas Drive Wells" JPT
- Fetkovich, M.J. (1973) "The Isochronal Testing of Oil Wells" SPE 4529
