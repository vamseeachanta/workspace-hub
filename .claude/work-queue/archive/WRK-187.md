---
id: WRK-187
title: 'Improve /improve: usage-based skill health, classify retry, apply API content'
status: archived
percent_complete: 100
priority: medium
complexity: medium
created_at: 2026-02-17 00:00:00+00:00
source: WRK-184-followup
target_repos:
- workspace-hub
module: automation
tags:
- improve
- robustness
- skills
- knowledge-graph
related:
- WRK-184
- WRK-205
blocked_by: []
synced_to: []
provider: claude
spec_ref: ''
plan_reviewed: true
plan_approved: true
plan_workstations: [ace-linux-1]
execution_workstations: [ace-linux-1]
---
# WRK-187: Improve /improve — Usage-Based Skill Health, Retry, API Content

## What
Address remaining gaps in the /improve pipeline. The primary change is a rethink
of how skill ecosystem health is measured: replace arbitrary count thresholds with
usage-based staleness detection, contingent on the skill index/knowledge graph
being effectively maintained.

## Items

### 1. Replace Count Thresholds with Usage-Based Staleness Detection

**Current state (2026-02-19 review)**:
The ecosystem health check fires on raw counts — 350 total skills, 50 per category.
These numbers are arbitrary hardcoded literals with no empirical basis. The
`engineering/marine-offshore` category (54 skills) is legitimately large for its
domain and should not be flagged as problematic.

**Decision**: Remove raw count threshold limits. A large, well-indexed skill library
is not a problem — stale, unreferenced skills are.

**Fix**: Replace count-based signals with usage-based staleness signals:
- Track `last_used` timestamp per skill (written by the stop hook when a skill is invoked)
- Flag skills not referenced in any session for > N days (suggested: 90 days)
- Flag skills with no `tags`, no `related`, or missing YAML frontmatter (index quality)
- Surface these as actionable deprecation/archive candidates, not raw count warnings

**Prerequisite**: Skill index and knowledge graph must be effectively maintained
(YAML frontmatter complete, tags consistent, `related` links populated) for
staleness detection to be meaningful. If the index is not maintained, staleness
signals will be noisy — assess index quality first before implementing.

**Other thresholds to keep or drop**:
- Signal backlog threshold (50): keep — this is a process health signal, not a size signal
- Score threshold (0.6): keep — this drives action classification
- File size limits (CLAUDE.md 100 lines, memory 200 lines, rules 400 lines): keep —
  these are legible constraints with clear rationale (context budget, readability)

### 2. Classify Retry Logic
`classify.sh` has no retry on API failure — single attempt, then skip. Add:
- 1 retry with exponential backoff (5s delay)
- Timeout bump from 30s to 45s for large signal sets
- Log the API error response for debugging

### 3. Apply Phase: Actual API Content Generation
`apply.sh` claims "60% API" but uses 0% API — it just writes content verbatim from
classify phase. The classify prompt does all content generation, limiting quality.

**Fix**: For `enhance` actions, call the API with current file content + proposed
improvement to generate a properly integrated edit (not just appended text).
This makes enhancements context-aware.

## Acceptance Criteria
- [ ] Raw skill count thresholds (350 total, 50 per category) removed from ecosystem health check
- [ ] Usage-based staleness detection implemented (last_used tracking + 90-day flag)
- [ ] Skill index quality check added (missing frontmatter, tags, related links)
- [ ] Classify has 1 retry with backoff
- [ ] Apply uses API for enhance actions (optional — behind flag)
- [ ] All existing tests still pass
