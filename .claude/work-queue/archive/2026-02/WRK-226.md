---
id: WRK-226
title: Audit and improve agent performance files across Claude, Codex, and Gemini
status: archived
priority: high
complexity: medium
compound: false
created_at: 2026-02-20T00:00:00Z
target_repos:
  - workspace-hub
commit:
spec_ref:
related: [WRK-225, WRK-228, WRK-229, WRK-230, WRK-231, WRK-234]
blocked_by: []
synced_to: []
plan_reviewed: false
plan_approved: true
standing: true
cadence: weekly  # revisit weekly until context quality is stable and comfortable
auto_execute: true  # agent runs analysis autonomously; pauses before applying file edits for user review
trigger: scheduled
percent_complete: 100
completed_at: 2026-02-20T00:00:00Z
brochure_status: n/a
---
# Audit and improve agent performance files across Claude, Codex, and Gemini

## What

Diagnose agent context quality by mining actual session logs to identify noise injected at session start, then fix the source files and encode the findings as preflight checks in the session hooks. The diagnostic is data-driven — not a static file review.

## Why

Line-limit checks and manual trimming are not diagnostics — they don't reveal what noise actually reaches the agent. The session logs in `.claude/state/sessions/` contain the ground truth: what was loaded, what was irrelevant, what repeated across sessions, what caused wasted tokens or wrong decisions. That evidence should drive targeted fixes to `CLAUDE.md`, `MEMORY.md`, rules, and provider adapter files — and should then be enforced via preflight hooks so the same noise cannot re-enter.

## Scope

### Phase 1 — Session noise analysis
- Read recent session logs (`.claude/state/sessions/*.jsonl`) to extract what context files were loaded at session start
- Identify noise patterns: stale facts, redundant rules, over-verbose sections, context injected but never referenced, instructions that contradict each other
- Tally by source file (which file is the main noise emitter?)
- Do the same for Codex and Gemini where session logs exist

### Phase 2 — Curated fixes to source files
- For each identified noise pattern, trace back to the originating file (`CLAUDE.md`, `MEMORY.md`, topic files, rules, `CODEX.md`, `GEMINI.md`, `behavior-contract.yaml`)
- Apply targeted edits: remove stale facts, collapse redundant rules, sharpen over-verbose sections
- Cross-provider parity: if a critical rule (security, legal, git workflow) is missing from Codex/Gemini adapters, add it

### Phase 3 — Preflight hook enforcement
- Write a preflight check (or extend the existing `hooks/readiness/ensure-readiness.sh`) that validates context file health before a session starts:
  - Key facts in `MEMORY.md` are not older than N days (configurable)
  - No section in `CLAUDE.md` exceeds its stated budget
  - Provider adapter files (`CODEX.md`, `GEMINI.md`) are in sync with `behavior-contract.yaml`
- Hook should emit warnings (not hard blocks) with actionable fix hints

## Acceptance Criteria

- [ ] Analyse at least the 5 most recent session logs; extract and categorise noise by source file
- [ ] Produce a noise report listing the top issues with evidence (session reference, file, line)
- [ ] Apply curated fixes to identified source files (one file at a time, no bulk overwrite)
- [ ] Add or extend a preflight hook that catches the identified noise patterns on future session starts
- [ ] **Model currency check** — extend preflight hook to verify `model-registry.yaml` is current: (a) registry not >14 days old, (b) no hardcoded model IDs in scripts bypassing the registry (run `behavior-contract.yaml`'s grep check), (c) `update-model-ids.sh` wired into the WRK-231 morning cron for weekly online check; emit actionable warning if stale
- [ ] Document methodology and findings in `.claude/docs/agent-performance-audit.md`

## Plan

1. **Mine session logs** — Read `.claude/state/sessions/` (5 most recent `.jsonl` files); extract context-load events; tag each loaded section by source file; flag anything loaded but never cited in the session
2. **Categorise noise** — Group findings: (a) stale facts, (b) redundant rules duplicated across files, (c) over-verbose sections, (d) contradictory instructions, (e) missing cross-provider rules
3. **Trace to source files** — Map each noise pattern to its originating file; rank by noise volume
4. **Apply targeted fixes** — Edit each flagged file; one file per commit; no bulk overwrite; preserve all signal. **Pare aggressively** — if a section is noise, remove it; don't soften or compress, delete
5. **Write preflight hook** — Add/extend `hooks/readiness/ensure-readiness.sh` with checks derived from the noise findings; emit actionable warnings at session start
6. **Document** — Write `.claude/docs/agent-performance-audit.md` with noise report, fixes applied, and hook logic

**Execution constraints:**
- Agent runs steps 1–3 (log mining, noise categorisation, source tracing) fully autonomously
- Step 4 (file edits): present proposed deletions per file before applying; user approves each
- Step 5 (preflight hook): agent writes the hook autonomously, user reviews before commit
- If in doubt between aggressive cut and cautious trim, cut — then let user restore if needed
- User monitors and will issue corrections if changes are too drastic — agent should surface diffs, not assume

*Verify: session log analysis script runs cleanly; hook fires on session init; audit doc captures before/after evidence*

## Research References

- [YouTube: Agent performance / context file patterns](https://youtu.be/JTW_sEXLH_o?si=BtUdlPzCrgGaOVrd) — starting point for online research

---
*Source: "investigate and review the most important agent performance files i.e. claude.md and memory.md etc. for claude, for other ai agents codex and gemini"*

## Agentic AI Horizon

- Auditing and improving agent performance files (CLAUDE.md, AGENTS.md, GEMINI.md) directly improves every session's agent quality — high ecosystem compounding value.
- Agent instruction quality directly determines session output quality; this is a standing weekly item that compounds across all sessions.
- **Disposition: invest now** — standing weekly item; performance file quality is the highest-leverage recurring investment in the ecosystem; maintain the cadence.
