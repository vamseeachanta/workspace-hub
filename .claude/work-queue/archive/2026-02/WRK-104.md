---
id: WRK-104
title: "Expand drilling rig fleet dataset to all offshore and onshore rigs"
status: archived
priority: high
complexity: complex
compound: false
created_at: 2026-02-08T12:30:00Z
completed_at: 2026-02-12T00:00:00Z
target_repos:
  - worldenergydata
commit: 48aeddd
spec_ref:
related: [WRK-102, WRK-135, WRK-136, WRK-137]
blocked_by: []
synced_to: []
plan_reviewed: true
plan_approved: true
percent_complete: 100
plan_workstations: [ace-linux-1]
execution_workstations: [ace-linux-1]
---

# Expand Drilling Rig Fleet Dataset to All Offshore and Onshore Rigs

## What
Expand the existing rig fleet inventory (currently 16 rigs from WAR data) to include all known offshore and onshore drilling rigs. Source publicly available rig fleet data covering jackups, semisubs, drillships, platform rigs, land rigs, and other rig types worldwide.

## Why
The current fleet dataset only covers 16 rigs from a single source (WAR). A comprehensive fleet covering all offshore and onshore rigs enables fleet-wide analysis, market studies, rig selection for projects, and serves as the foundation for hull data (WRK-102) and engineering analysis workflows.

## Acceptance Criteria
- [x] Identify and ingest publicly available rig fleet data sources (BSEE, industry registries, etc.)
- [x] Add all offshore rig types: jackups, semisubs, drillships, tender-assist, platform rigs
- [x] Add onshore/land rig fleet data
- [x] Online rig spec collector crawls contractor websites for detailed specs (BOP, riser, derrick, hull)
- [ ] Spec collector supports both HTML detail pages and PDF spec sheet downloads *(deferred to WRK-134)*
- [x] Maintain existing schema structure (extend if needed for new rig types)
- [x] Rig type classification consistent with existing rig_type_overrides.csv pattern
- [x] Update rig_fleet.bin binary with expanded dataset
- [x] Data loader returns full fleet with filtering by rig type (offshore/onshore)
- [x] Unit tests for expanded dataset loading, type classification, and online spec collection

## Results
- **2,187 unique rigs** (target was ≥500) from WAR + Noble + Seadrill scrape data
- **14 rig types** represented (target was ≥8): jackup, semi, drillship, platform, submersible, land, tender, barge, intervention_vessel, inland_barge, workover, multi_purpose, coiled_tubing_rig, snubbing_unit
- **396 tests** all passing (WAR export, scrape parsing, collection, dedup, bridge, build)
- **Cross-reviewed**: 4 steps reviewed × 3 agents, all P1/P2 findings resolved
- **Deferred scope**: XLS historical (163 rigs), Transocean/Borr/Valaris scraping, spec PDF parsing → WRK-133/134/135

## Plan

### Cross-Review Summary

Reviewed by 3 agents (2026-02-13): Claude MINOR, Codex REQUEST_CHANGES, Gemini APPROVE.
Review files: `scripts/review/results/20260213T024447Z-WRK-104.md-plan-*.md`

Key findings addressed in this revision:
- P1: Source priority mismatch between plan and `deduplicator.py` → reconciled (code is correct)
- P1: Scope unbounded ("all rigs") → added concrete per-source targets and completion criteria
- P2: `RIG_NAME` vs `VESSEL_NAME` gap → added explicit mapping step in WAR export and bridge
- P2: Existing pipeline scripts not acknowledged → plan now modifies existing scripts, not creates new
- P2: URL patterns speculative → marked as "to be validated", added Step 0 discovery
- P2: Dedup quality gates missing → added match confidence and audit trail
- P3: Output path wrong (`fleet/` vs `curated/`) → corrected to `curated/`

### Exploration Summary

Two rig fleet systems exist in worldenergydata:

1. **Legacy `bsee/data/loaders/rig_fleet/`** — BSEE WAR-derived, 16 committed rigs in `rig_fleet.bin`, 1,557-row `rig_type_overrides.csv`, 20-field `RigFleetSchema`, 89 tests. WAR acquirer downloads full GOM activity data; `build_rig_fleet_from_war.py` script exists but the full fleet binary (`rig_fleet_full.bin`, 323 KB) lives only in `.local/`. **Uses `RIG_NAME` as primary identifier.**

2. **New `vessel_fleet/`** — broader module with `DrillingRigSchema` (50+ fields including BOP, riser, moonpool, jackup, onshore-rig fields), `DrillingRigEntry` model, 13 drilling operator configs. **Uses `VESSEL_NAME` as primary identifier** (required field in `BaseVesselSchema`). `DrillingRigSchema.RIG_NAME` is an optional alias.

3. **Existing pipeline** — already fully orchestrated in `scripts/vessel_fleet/`:
   - `ingest_xls_historical.py` — XLS parser + Parquet output
   - `collect_drilling_fleet.py` — loads all 13 operator KNOWN_VESSELS → Parquet
   - `enrich_from_registries.py` — EQUASIS/ABS/DNV enrichment
   - `enrich_from_government.py` — BOEM/Baker Hughes enrichment
   - `fuse_and_deduplicate.py` — merge all raw sources → dedup → validate → export to `curated/`
   - `run_full_pipeline.py` — orchestrates all steps end-to-end

4. **XLS historical** — 163 deepwater rigs (SS + DS), ~80 fields. Legal assessment: GREEN. Transposed layout.

5. **Deduplicator source priority** (existing code in `dedup/deduplicator.py`):
   ```
   manual (7) > contractor_spec_pdf (6) > contractor_fleet_page (5) = contractor_fsr (5)
   > xls_historical (4) > equasis/abs/dnv (3) > boem/baker_hughes (2) > bsee_war (1)
   ```
   This is correct: current contractor data should win over stale XLS (2008-2012 era), and spec PDFs (most detailed) should win over fleet page summaries.

6. **`VESSEL_NAME` / `RIG_NAME` gap** — The deduplicator indexes by `record.get("VESSEL_NAME")` (line 48). WAR fleet records use `RIG_NAME`, not `VESSEL_NAME`. Without mapping, WAR records would fall into orphans and never merge. Must add `VESSEL_NAME = RIG_NAME` when exporting WAR data to vessel_fleet format.

**Key insight**: The `vessel_fleet` module is the right target with its existing pipeline. This work item populates it with real data, adds the online spec collector, and bridges the legacy loader. Most pipeline scripts need *modification*, not creation from scratch.

### Completion Criteria (Bounded Scope)

| Source | Expected Count | Minimum for Done | Rig Types Covered |
|--------|---------------|------------------|-------------------|
| BSEE WAR | ~1,500 unique rig names | ≥1,000 | jackup, semi, drillship, platform, intervention |
| XLS historical | 163 deepwater | ≥150 (allow parse failures) | semi, drillship |
| Operator KNOWN_VESSELS | ~60 (from 13 configs) | ≥50 | all major offshore + land_rig |
| Online spec details | Transocean + Borr + Noble + Seadrill (105 rigs) | ≥80 enriched rigs | drillship, semi, jackup |
| Spec PDFs (downloadable) | 102 PDFs (26+31+28+17) | ≥50 parsed for detailed specs | drillship, semi, jackup |
| FSR PDFs | Valaris + remaining operators | ≥30 additional rigs | all offshore types |
| **Merged unique fleet** | **target: 800+** | **≥500 unique rigs** | **≥8 of 16 rig types** |

"Done" means: merged fleet has ≥500 unique rigs across ≥8 rig types, with offshore AND onshore represented.

### Implementation Steps

**Step 0: Validate contractor website patterns** (DONE 2026-02-13, revised with Puppeteer)

Two-pass validation: (1) raw HTTP with `WebFetch`, (2) headless Chrome with Puppeteer for blocked/JS-rendered sites.

- **Report**: `docs/data/rig-fleet-website-validation.md`
- **Scraper**: `scripts/vessel_fleet/scrape_contractor_fleets.js` (Puppeteer, headless Chrome)
- **Raw data**: `data/modules/vessel_fleet/raw/contractor_scrape/` (JSON + screenshots per operator)

| Operator | Pass 1 (HTTP) | Pass 2 (Puppeteer) | Rigs Named | Spec PDFs | Individual Rig Data? |
|----------|--------------|-------------------|-----------|-----------|---------------------|
| Transocean | **YES** (200) | N/A | 26 | 26 PDFs (image-based) | **YES** — HTML table |
| Borr | **YES** (200) | N/A | 31 | 31 PDFs | **YES** — HTML table |
| Noble | NO (403) | **YES** (200) | **31** | **28 PDFs** | **YES** — rig cards with WD, design, location, availability |
| Seadrill | NO (JS) | **YES** (200) | **17** | **17 tech sheet PDFs** | **YES** — rig cards with type, availability, ownership |
| Valaris | NO (403) | YES (200) | **0** (landing page only) | FSR PDF | **NO** — needs sub-page scrape or FSR PDF parse |
| Nabors | NO (404) | NO (404) | 0 | 0 | **NO** — no fleet page found |
| H&P | NO (JS) | YES (200) | 0 named (3 model classes) | 1 fact sheet | **PARTIAL** — FlexRig specs only |

**Revised totals**: 5 of 7 operators reached via Puppeteer. **105 rigs named** (26 Transocean + 31 Borr + 31 Noble + 17 Seadrill), **102 spec PDFs** available (26 + 31 + 28 + 17). Far exceeds the original ≥20 enrichment target.

**Key findings from Puppeteer pass**:
- **Noble** (richest scrape): 31 rig cards with design class, water depth, location, availability. 28 individual spec PDFs on `s201.q4cdn.com`. Types inferable: jackups (350-492 ft WD), semis (1,500-10,000 ft), drillships (12,000 ft).
- **Seadrill**: 17 rigs with explicit type labels (drillship/semi/jackup), availability, ownership. 17 tech sheet PDFs on `seadrill.com/wp-content/uploads/`. FSR PDF also available.
- **Valaris**: Landing page with 4 sub-fleet links (jackups, semis, drillships, managed platforms). FSR PDF at `s23.q4cdn.com`. Needs Phase 2 sub-page scrape.
- **H&P**: FlexRig model specs captured (Flex3/Flex5/Flex3W Arabia — hookload, mud system, top drive, mobility). Individual rigs not listed (typical for land contractors).

**Decisions updated**:
- Step 4 expanded: Transocean + Borr + **Noble + Seadrill** (105 rigs, 102 spec PDFs)
- Valaris: add sub-page scrape to Step 4 (or FSR PDF fallback)
- H&P: FlexRig model specs as rig class templates; individual rigs from FSR if available
- Nabors: KNOWN_VESSELS only (no fleet page exists)

**Config updates applied**: Transocean `fleet_url` → `https://www.deepwater.com/our-fleet/our-rigs`; Borr `fleet_url` → `https://www.borrdrilling.com/our-fleet`

**Step 1: Build full WAR fleet and export to vessel_fleet format** (~1,500 rigs from BSEE)
- **Run**: `scripts/build_rig_fleet_from_war.py` to download WAR data and build fleet
- **Files**: `data/modules/bsee/.local/war/` (WAR cache), `data/modules/bsee/.local/rig_fleet/rig_fleet_full.bin` (output)
- **Apply**: existing `rig_type_overrides.csv` (1,557 classifications)
- **NEW — WAR-to-vessel_fleet export**: add script `scripts/vessel_fleet/export_war_to_vessel_fleet.py` that:
  1. Reads WAR fleet DataFrame
  2. Maps `RIG_NAME` → `VESSEL_NAME` (copy, keep both columns)
  3. Maps `DATA_SOURCE="bsee_war"` to vessel_fleet format
  4. Sets `VESSEL_CATEGORY="drilling_rig"`, `IS_OFFSHORE=True`
  5. Writes to `data/modules/vessel_fleet/raw/bsee_war/war_fleet.parquet`
- **Verify**: count unique rigs ≥1,000, check type distribution matches override CSV, confirm `VESSEL_NAME` populated for all records

**Step 2: Ingest XLS historical data** (163 deepwater rigs)
- **Run**: existing `scripts/vessel_fleet/ingest_xls_historical.py` with master XLS file
- **Files**: `src/worldenergydata/vessel_fleet/parsers/xls.py` (parser), output to `data/modules/vessel_fleet/raw/xls_historical/`
- **Parsing**: transpose rig-per-column layout, handle mixed formats (`"8,000 ft."`, `"20 x 40"`, `"DP2"`, `"Y/Yes/1.0"`)
- **Verify**: ≥150 rigs output, spot-check 5 rigs against source for field accuracy

**Step 3: Collect operator fleet data** (13 drilling operators)
- **Modify**: existing `scripts/vessel_fleet/collect_drilling_fleet.py` — currently only loads KNOWN_VESSELS; extend to also attempt `FleetPageCollector.collect()` per operator with KNOWN_VESSELS as fallback
- **Files**: `src/worldenergydata/vessel_fleet/collectors/fleet_page_collector.py` (existing), output to `data/modules/vessel_fleet/raw/drilling_contractors/` (existing path)
- **Operators**: all 13 configs in `vessel_fleet/configs/drilling/`
- **Note**: Nabors, Patterson-UTI, H&P are land rig operators — covers onshore criterion. Their KNOWN_VESSELS are sparse (1-2 entries); web scraping may yield more but is not guaranteed.
- **Verify**: ≥50 total rigs collected, per-operator counts logged

**Step 4: Online rig spec collector** (enrich fleet from contractor websites + spec PDFs)
- **Scope** (expanded by Puppeteer pass): Transocean (26) + Borr (31) + Noble (31) + Seadrill (17) = **105 rigs, 102 spec PDFs**. Plus Valaris sub-page scrape or FSR PDF.
- **New file**: `src/worldenergydata/vessel_fleet/collectors/rig_spec_collector.py`
- **Puppeteer scrape data**: `data/modules/vessel_fleet/raw/contractor_scrape/*.json` (pre-collected)

**4a. Transocean fleet page + spec PDFs** (26 rigs)
- Scrape `https://www.deepwater.com/our-fleet/our-rigs` — static HTML table
- Extract rig name, type, water depth from table columns
- Download each rig's spec PDF from `/documents/RigSpecs/{Rig Name}.pdf`
- Parse PDFs: try `pdfplumber` first; if image-based, log warning and keep fleet-table data only (OCR out of scope)
- Output: `data/modules/vessel_fleet/raw/spec_details/transocean.parquet`

**4b. Borr fleet page + spec PDFs** (31 rigs)
- Scrape `https://www.borrdrilling.com/our-fleet` — parse HTML table (use `<table>` structure, not CSS classes)
- Extract: RIG NAME, DESIGN, BUILDER, YEAR BUILT, WATER DEPTH from table
- Download spec PDFs from `api.borrdrilling.com/wp-content/uploads/...` links
- Parse PDFs with `pdfplumber` for BOP, riser, derrick, moonpool specs
- Output: `data/modules/vessel_fleet/raw/spec_details/borr.parquet`

**4c. Noble fleet + spec PDFs** (31 rigs, NEW — from Puppeteer scrape)
- Parse pre-collected JSON from `contractor_scrape/noble.json` (31 rig cards already extracted)
- Available fields per rig: name, design class, water depth, location, availability date
- Rig type classification: jackups (WD ≤500 ft), semis (500-10,000 ft), drillships (≥12,000 ft)
- Download 28 individual spec PDFs from `s201.q4cdn.com` links (already captured in JSON)
- Parse PDFs with `pdfplumber` for hookload, VDL, BOP, derrick, DP class
- Output: `data/modules/vessel_fleet/raw/spec_details/noble.parquet`

**4d. Seadrill fleet + tech sheet PDFs** (17 rigs, NEW — from Puppeteer scrape)
- Parse pre-collected JSON from `contractor_scrape/seadrill.json` (17 rigs with explicit types)
- Available fields per rig: name, explicit type (drillship/semi/jackup), availability, ownership
- Download 17 individual tech sheet PDFs from `seadrill.com/wp-content/uploads/` links
- Parse PDFs for detailed specs
- Output: `data/modules/vessel_fleet/raw/spec_details/seadrill.parquet`

**4e. Valaris sub-page scrape + FSR PDF** (NEW)
- Use Puppeteer script to scrape 4 sub-fleet pages found in Step 0:
  - `valaris.com/our-fleet/drillships/default.aspx`
  - `valaris.com/our-fleet/semisubmersibles/default.aspx`
  - `valaris.com/our-fleet/jackups/default.aspx`
  - `valaris.com/our-fleet/managed-platforms/default.aspx`
- Fallback: download FSR PDF from `s23.q4cdn.com` and parse with `pdfplumber`
- Output: `data/modules/vessel_fleet/raw/spec_details/valaris.parquet`

**4f. Fleet Status Report (FSR) PDF parsing** (supplementary)
- **New file**: `src/worldenergydata/vessel_fleet/collectors/fsr_collector.py`
- Download latest FSR PDFs for operators not fully covered by fleet page scraping
- Parse tabular PDF content with `pdfplumber`: rig name, type, water depth, year built, design, contract status
- Set `DATA_SOURCE="contractor_fsr"` (priority 5 in deduplicator)
- Output: `data/modules/vessel_fleet/raw/fsr/` per operator

**Shared infrastructure**:
- Extend `ContractorConfig` with optional: `spec_pdf_pattern`, `fsr_url`, `detail_field_mapping`
- Rate limiting: `BaseCollector.rate_limit` (0.5 req/s)
- Caching: `data/modules/vessel_fleet/.local/spec_cache/{operator}/` with 30-day TTL
- Graceful degradation: if PDF parse fails, log warning, keep fleet-table data
- **Verify**: ≥80 rigs enriched with spec details; ≥50 spec PDFs parsed; spot-check 5 rigs against public data

**Step 5: Merge, deduplicate, produce unified fleet**
- **Modify**: existing `scripts/vessel_fleet/fuse_and_deduplicate.py` — already reads all `raw/` subdirs, deduplicates, validates, and writes to `curated/`
- **Source priority**: use existing `_SOURCE_PRIORITY` in `dedup/deduplicator.py` (correct as-is):
  `contractor_spec_pdf (6) > contractor_fleet_page (5) > xls_historical (4) > bsee_war (1)`
- **Fix dedup for WAR records**: WAR export (Step 1) now sets `VESSEL_NAME`, so deduplicator will correctly index by name. No code change needed in deduplicator itself.
- **Dedup quality gates** (new):
  - Log merge audit trail: for each merged record, track `_merge_sources` list showing which sources contributed
  - After dedup, report: total records in, unique out, orphan count, source distribution
  - Flag rigs with same normalized name but conflicting `RIG_TYPE` for manual review
  - Export `curated/merge_audit.csv` with per-rig source provenance
- **Output**: `data/modules/vessel_fleet/curated/drilling_rigs.parquet` + `drilling_rigs.csv` (existing path)
- **Verify**: ≥500 unique rigs, ≥8 rig types, offshore AND onshore present, completeness report via `quality/completeness.py`

**Step 6: Bridge legacy bsee rig_fleet loader**
- **Edit**: `src/worldenergydata/bsee/data/loaders/rig_fleet/rig_fleet_loader.py`
- **Change**: add new fallback tier that reads from `vessel_fleet` curated Parquet when available, inserted between `.local/` and `bin/` in the fallback chain:
  1. Config override (existing)
  2. `.local/` directory (existing)
  3. **NEW**: `vessel_fleet/curated/drilling_rigs.parquet` → map `VESSEL_NAME` back to `RIG_NAME`, filter `VESSEL_CATEGORY="drilling_rig"`
  4. `bin/` directory (existing, 16-rig sample)
- **Column mapping** (vessel_fleet → bsee legacy):
  - `VESSEL_NAME` → `RIG_NAME`
  - `VESSEL_TYPE` → `RIG_TYPE` (if `RIG_TYPE` not already set)
  - `STATUS` → `RIG_STATUS` (if not set)
  - `OWNER`, `OPERATOR`, `IMO_NUMBER`, `FLAG_STATE` — same names, direct pass-through
- **Add**: `DataSource.VESSEL_FLEET = "vessel_fleet"` enum value in `constants.py`
- **Preserve**: all existing APIs (`get_rigs_by_type`, `get_rigs_by_offshore_status`, `build_fleet_from_war`, `get_rig_well_history`)
- **Verify**: existing 89 tests still pass, new data accessible through legacy API

**Step 7: Build expanded rig_fleet.bin**
- **Script**: add `scripts/build_unified_fleet.py` that reads `curated/drilling_rigs.parquet` → maps to legacy schema → writes `rig_fleet.bin` compatible pickle
- **Output**: `data/modules/bsee/bin/rig_fleet/rig_fleet.bin` updated with ~50 representative rigs (committed sample covering all major types); full fleet stays in `curated/` Parquet (gitignored)
- **Canonical artifact**: Parquet in `curated/` is now the canonical fleet; `rig_fleet.bin` is a sampled compatibility artifact for the legacy loader when Parquet is unavailable
- **Verify**: loader reads expanded binary correctly, filtering by type and offshore status works

**Step 8: Tests**
- **Extend existing**: `tests/modules/vessel_fleet/dedup/test_deduplicator.py` — add tests for WAR record merge (VESSEL_NAME mapping), source priority verification, merge audit trail, conflicting RIG_TYPE flagging
- **Extend existing**: `tests/modules/vessel_fleet/quality/test_validator.py` — add completion criteria checks (≥500 rigs, ≥8 types)
- **New tests**: `tests/modules/vessel_fleet/collectors/test_rig_spec_collector.py` — detail page discovery, HTML spec parsing, PDF spec extraction, field mapping, cache TTL, graceful 404 handling. Use mock HTTP responses with real contractor page HTML fixtures.
- **New tests**: `tests/modules/vessel_fleet/test_war_export.py` — WAR → vessel_fleet format mapping, VESSEL_NAME populated, DATA_SOURCE correct
- **Update tests**: `tests/modules/bsee/data/loaders/rig_fleet/test_rig_fleet_loader.py` — add tests for vessel_fleet Parquet fallback path, column mapping (VESSEL_NAME → RIG_NAME)
- **Verify**: all 89 existing rig fleet tests pass + new tests pass
- **Run**: `PYTHONPATH="src:../assetutilities/src" python3 -m pytest tests/modules/bsee/data/loaders/rig_fleet/ tests/modules/vessel_fleet/ -v --tb=short --noconftest`

### Test Strategy
- Unit tests for each step (WAR export, XLS parse, operator ingest, online spec collection, merge, bridge)
- Integration test: run `scripts/vessel_fleet/run_full_pipeline.py` end-to-end, verify curated output meets completion criteria
- Online collector tests: mock HTTP responses with real contractor page HTML fixtures (saved from Step 0 validation)
- Dedup quality: assert merge audit trail populated, no duplicate IMOs, conflicting types flagged
- Regression: existing 89 rig fleet tests must not break
- Completion gate: merged fleet ≥500 unique rigs, ≥8 of 16 rig types, offshore AND onshore present

### Risk & Mitigations
- **WAR download may timeout**: WAR acquirer has 30-day cache; run once, subsequent loads use cache
- **XLS parser may fail on edge cases**: `numeric.py` parser exists for mixed format handling; add specific tests for `"8,000 ft."` patterns
- **Operator fleet pages may change**: configs have static KNOWN_VESSELS fallback — stable baseline even if scraping fails
- **Contractor detail pages may be JS-rendered**: Step 0 validates before committing to Step 4. If <3 operators scrapable, defer online spec collector to follow-up WRK. No `playwright` dependency in this WRK.
- **Rate limiting / robots.txt**: `BaseCollector` enforces rate limiting; add `robots.txt` check before first request per domain
- **RIG_NAME / VESSEL_NAME mismatch**: Explicitly handled in Step 1 (WAR export maps RIG_NAME → VESSEL_NAME) and Step 6 (bridge maps back). Both directions tested.
- **Dedup false merges**: Merge audit trail (`curated/merge_audit.csv`) enables post-hoc review. Conflicting RIG_TYPE entries flagged for manual inspection.
- **Land rig operator coverage sparse**: Nabors/Patterson-UTI/H&P KNOWN_VESSELS have 1-2 entries each. Online spec collection (Step 4) may yield more. Accept sparse onshore data for this WRK; expand in follow-up.
- **Legal compliance**: XLS data rated GREEN. Online spec collection uses only publicly available marketing data. No subscription/login-gated sources. `DATA_SOURCE_URL` field provides attribution per record.

---
*Source: add to worldenergydata repo, add all offshore and onshore rigs to the drilling rig fleet dataset*
