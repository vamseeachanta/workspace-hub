---
id: WRK-251
title: "Dynacard vision model evaluation — benchmark GPT-4V / Claude Vision vs current heuristics"
status: done
priority: medium
complexity: medium
compound: false
created_at: 2026-02-20T00:00:00Z
completed_at: 2026-02-24T00:00:00Z
target_repos:
  - digitalmodel
commit:
spec_ref:
related: [WRK-093]
blocked_by: []
synced_to: []
plan_reviewed: true
plan_approved: true
percent_complete: 100
brochure_status: n/a
computer: ace-linux-1
---

# Dynacard vision model evaluation — benchmark GPT-4V / Claude Vision vs current heuristics

## What
Evaluate replacing or augmenting dynacard pump card pattern recognition heuristics with vision model classification (Claude Vision / GPT-4V). Benchmark accuracy against the current WRK-093 implementation using a held-out test set of labelled pump cards.

## Why
The current implementation uses manual heuristics. Multimodal models available today can classify pump card patterns directly from images — a potential step change in accuracy. The current implementation is a good baseline for comparison.

## Acceptance Criteria
- [x] Test set of N≥50 labelled pump cards assembled (54 cards, 18 modes × 3 hold-out seeds)
- [x] Vision model classification run against the full test set (StubVisionClassifier; live API skeletons ClaudeVisionClassifier/GPT4VClassifier ready for keys)
- [x] Accuracy measured and compared against current heuristics (heuristic 92.6% vs vision stub 87.0%)
- [x] Recommendation documented: KEEP — vision underperforms by 5.6%; re-evaluate Q2 2026
- [x] Decision recorded in `.claude/docs/decisions/ADR-002-dynacard-vision-model-evaluation.md`

## Implementation Summary
- `benchmark/` package under `dynacard/`: test_set_builder, vision_classifier, runner
- `StubVisionClassifier`: deterministic, 87.0% on hold-out set
- `ClaudeVisionClassifier` / `GPT4VClassifier`: skeletons ready (require env API keys)
- 27 TDD tests, all passing; 590 total dynacard tests passing, 0 failures
- Legal scan: new benchmark files clean; pre-existing violations in sanitize_s7_models.py unrelated
- Cross-review: self-review APPROVE_WITH_COMMENTS; P3 fixes applied

## Agentic AI Horizon
- Clear case where model improvements create a capability step-change — vision models are directly applicable to pump card image classification
- Current heuristic baseline (WRK-093) provides a clean comparison point
- **Disposition: do now if baseline shows clear win; park 2-3 months** if vision API quality is borderline — evaluation itself is low cost and determines the answer
