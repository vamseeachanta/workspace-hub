---
id: WRK-118
title: "AI agent utilization strategy — leverage Claude, Codex, Gemini for planning, development, testing workflows"
status: working
priority: medium
complexity: complex
created_at: 2026-02-11T00:00:00Z
target_repos:
  - workspace-hub
commit:
spec_ref: specs/wrk/WRK-118/plan.md
related:
  - WRK-199
blocked_by: []
synced_to: []
plan_reviewed: false
plan_approved: true
percent_complete: 0
brochure_status: n/a
computer: ace-linux-1
provider: claude
provider_alt:
task_agents:
  phase_1: gemini   # audit archived items, derive role matrix
  phase_2: claude   # author delegation templates doc
  phase_3: codex    # wire task_classifier into work queue scripts
  phase_4: claude   # design assessment scaffolding
  phase_5: claude   # validate on 3 real items
---

# AI Agent Utilization Strategy

## What
Define and implement a systematic strategy for utilizing available AI agents (Claude Code, Codex CLI, Gemini CLI) across the full development lifecycle: planning, architecture, implementation, testing, code review, and documentation. Establish clear role assignments, handoff patterns, and quality gates that leverage each agent's strengths.

## Why
Multiple AI agents are available (Claude Code as orchestrator, Codex CLI and Gemini CLI for cross-review) but usage is currently ad-hoc — mostly limited to cross-review of completed work. A deliberate strategy would maximize agent utilization across all phases: using agents for upfront planning validation, parallel implementation exploration, automated test generation, documentation drafting, and continuous review — not just post-hoc review.

## Acceptance Criteria
- [ ] Audit current agent capabilities and limitations (Claude Code, Codex CLI, Gemini CLI)
- [ ] Define role matrix: which agent handles which workflow phase (planning, coding, testing, review, docs)
- [ ] Document agent invocation patterns for each phase (commands, flags, input/output formats)
- [ ] Create agent delegation templates for common tasks (feature implementation, bug fix, refactor, test writing)
- [ ] Establish quality gates that require multi-agent consensus (e.g., 2-of-3 approve before merge)
- [ ] Integrate agent utilization into work queue routing (Route A/B/C agent assignments)
- [ ] Test the strategy on 2-3 real work items from the queue
- [ ] Document lessons learned and refine the strategy

## Plan

**Phase 1 — Audit & role matrix** *(Gemini)*
- Scan `.claude/work-queue/archive/` for actual provider usage patterns by task type
- Derive empirical role matrix from real data, not assumptions
- Extend `behavior-contract.yaml` strengths block with task-type granularity
  (feature | bugfix | refactor | test-writing | research | docs → primary + rationale)

**Phase 2 — task_agents delegation templates** *(Claude)*
- Author `docs/modules/ai/agent-delegation-templates.md`
- Standard `task_agents:` maps for each task type × route (A/B/C):
  - feature/A → codex | feature/B → claude plan + codex impl | feature/C → claude + codex + gemini
  - bugfix → codex diagnose+fix + claude review
  - refactor → codex + gemini summary
  - test-writing → codex primary + claude review
  - research/docs → gemini primary + claude synthesize
- Referenced by WRK-199 as the decision table it automates

**Phase 3 — Wire task_classifier into /work run** *(Codex)*
- Add routing recommendation step to work.sh pre-plan gate
- Call `scripts/coordination/routing/lib/task_classifier.sh` → `provider_recommender.sh`
- Auto-populate `task_agents:` in WRK frontmatter from recommendation
- Display rationale: "Recommending Codex (phase 2-3): focused code task, Claude quota at 7%(S)"

**Phase 4 — Provider assessment scaffolding** *(Claude)*
- Create `.claude/state/provider-assessments/` directory + YAML template
- Wire post-cross-review step: write assessment entry per reviewer verdict
- Add quarterly report trigger to work.sh

**Phase 5 — Validate on 3 items** *(Claude)*
- Apply routing to WRK-199, WRK-184, WRK-186
- Confirm task_agents populated correctly and rationale is sensible
- Adjust templates if recommendations drift

*Approved by user: 2026-02-18*

---
*Source: add to utilize available ai agents for planning, development, testing etc.*

## Agentic AI Horizon

- AI agent utilisation strategy (Claude/Codex/Gemini allocation) is meta-level infrastructure that directly governs how well all other work is executed — the highest-leverage planning document in the queue.
- Provider allocation strategies will shift as model capabilities converge; the plan should be living and revisable rather than locked in.
- **Disposition: invest now** — standing work item; keep the strategy current and revisable; it's the backbone of all agentic execution decisions.
