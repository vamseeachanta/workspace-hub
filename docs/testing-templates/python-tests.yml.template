# Python Tests GitHub Actions Workflow Template
#
# Copy this file to .github/workflows/python-tests.yml
# Customize the Python versions, OS, and dependencies as needed

name: Python Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - '**/*.py'
      - 'requirements*.txt'
      - 'pyproject.toml'
      - 'setup.py'
      - 'setup.cfg'
      - '.github/workflows/python-tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - '**/*.py'
      - 'requirements*.txt'
      - 'pyproject.toml'
      - 'setup.py'
      - 'setup.cfg'
  workflow_dispatch:
  schedule:
    # Run tests every Sunday at 2 AM UTC
    - cron: '0 2 * * 0'

env:
  # Global environment variables
  PYTHONUNBUFFERED: 1
  FORCE_COLOR: 1

jobs:
  test:
    name: Test on Python ${{ matrix.python-version }} (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
        os: [ubuntu-latest, windows-latest, macos-latest]
        # Exclude combinations if needed
        exclude:
          - os: windows-latest
            python-version: '3.9'
          - os: macos-latest
            python-version: '3.9'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    # Alternative: Use uv for faster dependency installation
    # - name: Install uv
    #   uses: astral-sh/setup-uv@v1
    #   with:
    #     version: "latest"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
      # Alternative with uv:
      # run: |
      #   uv pip install -r requirements.txt
      #   uv pip install -r requirements-test.txt

    - name: Install project in development mode
      run: pip install -e .
      # Alternative with uv:
      # run: uv pip install -e .

    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics

    - name: Type checking with mypy
      run: mypy src/ --ignore-missing-imports
      continue-on-error: true

    - name: Security check with bandit
      run: bandit -r src/ -f json -o bandit-report.json
      continue-on-error: true

    - name: Run tests with pytest
      run: |
        pytest \
          --cov=src \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=80 \
          --junitxml=pytest.xml \
          --verbose
      env:
        # Environment variables for testing
        TESTING: true
        DATABASE_URL: sqlite:///:memory:

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}-${{ matrix.os }}
        path: |
          pytest.xml
          htmlcov/
          bandit-report.json
        retention-days: 30

    - name: Upload coverage reports
      uses: actions/upload-artifact@v3
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      with:
        name: coverage-report
        path: |
          coverage.xml
          htmlcov/
        retention-days: 30

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: test
    timeout-minutes: 45

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        pip install -e .

    - name: Wait for services
      run: |
        # Wait for PostgreSQL
        until pg_isready -h localhost -p 5432; do sleep 1; done
        # Wait for Redis
        until redis-cli -h localhost -p 6379 ping; do sleep 1; done

    - name: Run integration tests
      run: |
        pytest tests/integration/ \
          --cov=src \
          --cov-report=xml \
          --verbose \
          -m "integration"
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379/0
        TESTING: true

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [test, integration-tests]
    if: always()

    steps:
    - name: Check test results
      run: |
        if [[ "${{ needs.test.result }}" != "success" ]]; then
          echo "‚ùå Unit tests failed"
          exit 1
        fi
        if [[ "${{ needs.integration-tests.result }}" != "success" ]]; then
          echo "‚ùå Integration tests failed"
          exit 1
        fi
        echo "‚úÖ All tests passed"

    - name: Quality gate passed
      run: echo "üéâ Quality gate passed! Ready for deployment."